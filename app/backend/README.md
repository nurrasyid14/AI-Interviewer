# ðŸ§  AI Interviewer â€” Backend Architecture

This backend module powers the **AI Interviewer**, a conversational system designed for automated evaluation of applicant responses using **Machine Learning**, **Text Mining**, and **I/O Psychology** metrics (based on Lawsheâ€™s Reliability thresholds).

---

## âš™ï¸ Core Objective

To simulate an intelligent interviewer that:
- Receives multilingual interview responses (speech or text).
- Translates, cleans, and normalizes linguistic data.
- Evaluates semantic **relevance**, **sentiment**, and **reliability**.
- Aggregates decision metrics for final **acceptance classification**.

---

## ðŸ§© Backend Folder Overview

backend/
â”œâ”€â”€ api_call/ # Handles API endpoints & communication layer
â”‚
â”œâ”€â”€ context_classifier/ # Classifies context/topic of responses
â”‚
â”œâ”€â”€ decisionmaker/ # Core logic for acceptance/rejection based on metrics
â”‚
â”œâ”€â”€ learning_evaluation/ # Evaluates model learning, metrics, and reliability
â”‚
â”œâ”€â”€ preprocessor/ # Complete text preprocessing and translation pipeline
â”‚ â”œâ”€â”€ ingestion/ # Input handling (speech/text), multilingual translation
â”‚ â”œâ”€â”€ text_cleaning/ # Normalization, stopword removal, tokenization
â”‚ â”œâ”€â”€ linguistics/ # Lemmatization & stemming
â”‚ â”œâ”€â”€ feature_extraction/# TF-IDF, BoW, and word embeddings
â”‚ â””â”€â”€ preprocessor_pipeline.py # Orchestrates preprocessing flow
â”‚
â”œâ”€â”€ relevance/ # Determines semantic & topical relevance of responses
â”‚
â”œâ”€â”€ reporter/ # Summarizes and reports evaluation results
â”‚
â”œâ”€â”€ sentiment/ # Sentiment and affective tone analysis
â”‚
â””â”€â”€ init.py

---

## ðŸ” System Pipeline

[Input Speech/Text]
â†“
ðŸ§© Preprocessing
â”œâ”€ Translation & Cleaning
â”œâ”€ Tokenization & Lemmatization
â””â”€ Feature Vectorization (TF-IDF / Embeddings)
â†“
ðŸ“Š Subsetting & Ensemble Learning
â”œâ”€ Model Partitioning (K-Fold / Leave-One-Out)
â”œâ”€ Ensemble Voting (RF / SVM / NB / DTree)
â†“
ðŸ§  Decision Making
â”œâ”€ Reliability Scoring (0â€“1 scale)
â”œâ”€ Acceptance if R >= 0.75 (Lawshe threshold)
â†“
ðŸ’¬ Sentiment & Relevance Evaluation
â”œâ”€ Sentiment tone consistency
â””â”€ Contextual match with question intent
â†“
ðŸ“„ Reporting
â”œâ”€ Generates reliability report
â”œâ”€ Stores results under /data/reports
â””â”€ Feeds data to frontend visualizations (Plotly)

---

## ðŸ§± Key Components

### ðŸ”¹ **1. Preprocessor**
Handles all text ingestion, normalization, and linguistic transformation:
- `translator.py` â†’ Converts all responses to English for model consistency.
- `tokenizer.py`, `lemmatizer_stemmer.py` â†’ Standardize linguistic inputs.
- `tf_idf.py`, `word_embedding.py` â†’ Vectorize text for learning models.

### ðŸ”¹ **2. Relevance**
Computes semantic similarity between candidate answers and the intended question using:
- Cosine similarity or sentence embeddings.
- Threshold tuning to align with I/O Psychology interpretability.

### ðŸ”¹ **3. Sentiment**
Analyzes applicant emotional tone and assertiveness for personality estimation:
- Polarity & subjectivity scoring.
- Emotional stability as an interpretive feature in reliability metrics.

### ðŸ”¹ **4. Decision Maker**
Aggregates outputs of Ensemble Models + Relevance + Sentiment + Reliability to decide:
> **ACCEPT** if Reliability â‰¥ 0.75  
> **REJECT** otherwise.

### ðŸ”¹ **5. Reporter**
Compiles all logs and analytical summaries:
- Reliability score report
- Sentiment polarity chart (Plotly)
- Data export to `data/reports/`

## Folder Structure

app/
â””â”€â”€ backend/
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ api_call/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ external_services.py          # Optional: translation or verification APIs
    â”‚   â”œâ”€â”€ fastapi_router.py             # REST endpoints for frontend
    â”‚   â”œâ”€â”€ websocket_handler.py          # Real-time feedback or dashboard updates
    â”‚   â””â”€â”€ schema_models.py              # Pydantic models for request/response data
    â”‚
    â”œâ”€â”€ context_classifier/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ context_classifier.py         # Topic/context detection of interview Q&A
    â”‚
    â”œâ”€â”€ preprocessor/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ [ingestion]/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ input_handler.py
    â”‚   â”‚   â”œâ”€â”€ audio_transcriber.py
    â”‚   â”‚   â””â”€â”€ translator.py
    â”‚   â”œâ”€â”€ [text_cleaning]/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ normalizer.py
    â”‚   â”‚   â”œâ”€â”€ stopword_remover.py
    â”‚   â”‚   â””â”€â”€ tokenizer.py
    â”‚   â”œâ”€â”€ [linguistics]/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ lemmatizer_stemmer.py
    â”‚   â”‚   â””â”€â”€ pos_tagger.py
    â”‚   â”œâ”€â”€ [feature_extraction]/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ bag_of_words.py
    â”‚   â”‚   â”œâ”€â”€ tf_idf.py
    â”‚   â”‚   â””â”€â”€ word_embedding.py
    â”‚   â””â”€â”€ preprocessor_pipeline.py
    â”‚
    â”œâ”€â”€ subset/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ k_fold.py
    â”‚   â”œâ”€â”€ leave_one_out.py
    â”‚   â”œâ”€â”€ cluster_subset.py
    â”‚   â””â”€â”€ subset_utils.py
    â”‚
    â”œâ”€â”€ ensemble/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ random_forest.py
    â”‚   â”œâ”€â”€ neural_network.py
    â”‚   â”œâ”€â”€ svm.py
    â”‚   â”œâ”€â”€ naive_bayes.py
    â”‚   â””â”€â”€ ensemble_controller.py
    â”‚
    â”œâ”€â”€ learning_evaluation/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ metrics.py                    # Accuracy, F1, precision, recall
    â”‚   â”œâ”€â”€ calibration.py                # Probability calibration & reliability
    â”‚   â”œâ”€â”€ bias_analysis.py              # Fairness metrics
    â”‚   â””â”€â”€ evaluation_pipeline.py        # Interfaces with ensemble & visualizer
    â”‚
    â”œâ”€â”€ relevance/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ relevance_evaluator.py        # Cosine similarity / semantic match
    â”‚   â””â”€â”€ topic_alignment.py            # Theme matching for question-answer pairs
    â”‚
    â”œâ”€â”€ sentiment/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ sentiment_analyzer.py         # Polarity & affect detection
    â”‚   â””â”€â”€ tone_model.py                 # Prosody or voice tone model
    â”‚
    â”œâ”€â”€ reliability/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ lawshes_cvr.py                # Content Validity Ratio (I/O Psychology)
    â”‚   â”œâ”€â”€ cronbach_alpha.py             # Internal consistency
    â”‚   â”œâ”€â”€ reliability_metric.py         # Aggregation of reliability scores
    â”‚   â””â”€â”€ reliability_reporter.py       # Sends summarized reliability results
    â”‚
    â”œâ”€â”€ decisionmaker/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ decision_rules.py             # Accept/Reject logic
    â”‚   â”œâ”€â”€ threshold_logic.py
    â”‚   â”œâ”€â”€ explainability.py             # Justifications for decisions
    â”‚   â””â”€â”€ decision_logger.py
    â”‚
    â”œâ”€â”€ reporter/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ db_connector.py               # PostgreSQL interface for metadata/results
    â”‚   â”œâ”€â”€ result_logger.py              # Saves run summaries
    â”‚   â”œâ”€â”€ report_generator.py           # Converts results â†’ structured report
    â”‚   â””â”€â”€ dashboard_updater.py          # Updates live user dashboards
    â”‚
    â”œâ”€â”€ visualizer/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ [evaluation/]                 # Dev-focused visuals (learning/evaluation)
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ model_performance.py
    â”‚   â”‚   â”œâ”€â”€ confusion_matrix_plotter.py
    â”‚   â”‚   â””â”€â”€ reliability_distribution.py
    â”‚   â”œâ”€â”€ [user_dashboard/]             # End-user dashboards
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ reliability_overview.py
    â”‚   â”‚   â”œâ”€â”€ sentiment_chart.py
    â”‚   â”‚   â”œâ”€â”€ relevance_heatmap.py
    â”‚   â”‚   â””â”€â”€ overall_dashboard.py
    â”‚   â”œâ”€â”€ [shared_components/]          # Shared styling/utilities
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ plotly_theme.py
    â”‚   â”‚   â””â”€â”€ export_utils.py
    â”‚   â””â”€â”€ visualizer_pipeline.py        # Connects plots to frontend & reporter
    â”‚
    â”œâ”€â”€ pipeline_controller.py            # Orchestrates full AI Interviewer pipeline
    â”‚
    â””â”€â”€ utils/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ config_loader.py
        â”œâ”€â”€ language_tools.py
        â”œâ”€â”€ io_utils.py
        â””â”€â”€ logger.py


---

## ðŸ“ˆ Learning Evaluation & Subsetting

- **Subsetting:** K-Fold, Leave-One-Out, or Stratified Sampling to ensure robust reliability testing.
- **Ensemble Learning:** Random Forest, SVM, NaÃ¯ve Bayes, Decision Tree â€” trained via cross-validation.
- **Reliability Evaluation:** Cronbachâ€™s Alpha or Lawshe CVR for I/O Psychology validity.

---

## ðŸ§¾ Reliability Rule (I/O Psychology)

| Symbol | Description | Threshold |
|:-------|:-------------|:-----------|
| `R` | Reliability rate | 0â€“1 |
| `R >= 0.75` | Accept candidate (valid performance) |
| `R < 0.75` | Reject candidate (insufficient reliability) |

---

## ðŸ§° Dependencies (Installed via `requirements.txt`)

### --- CORE ENVIRONMENT ---
python-dotenv==1.0.1          # For .env configuration
numpy==1.26.4                 # Base math operations
pandas==2.2.3                 # Data handling (reports, logs, etc.)
scikit-learn==1.5.2           # ML models, ensemble learning, subsetting (KFold, LOOCV)
scipy==1.14.1                 # Statistical / psychometric computation

### --- NLP / TEXT MINING ---
nltk==3.9.1                   # Tokenization, stemming, stopwords
spacy==3.7.5                  # Linguistic parsing, POS tagging, NER
gensim==4.3.3                 # Word2Vec, TF-IDF, topic models
sentence-transformers==3.2.1  # Semantic embeddings (cross-lingual)
langdetect==1.0.9             # Auto-detect language
deep-translator==1.11.4       # Translate user input to English if needed

### --- AI / ENSEMBLE / MODEL HANDLING ---
xgboost==2.1.3                # Gradient boosting ensemble
lightgbm==4.3.0               # Efficient ensemble variant
joblib==1.4.2                 # Model persistence & caching
imbalanced-learn==0.12.3      # Handle dataset imbalance (psychology corpora often skewed)

### --- RELIABILITY / PSYCHOMETRICS ---
pingouin==0.5.4               # Reliability metrics (Cronbach Î±, ICC, etc.)
statsmodels==0.14.4           # Advanced statistical analysis
factor-analyzer==0.5.1        # Factor analysis for I/O psychology dimensions

### --- DATABASE / STORAGE ---
psycopg2-binary==2.9.10       # PostgreSQL connector
SQLAlchemy==2.0.36            # ORM for flexible database schema mapping

### --- VISUALIZATION (Plotly only) ---
plotly==5.24.1                # Interactive dashboard & reliability visualization
dash==2.18.2                  # Plotly Dash web interface (optional)
kaleido==0.2.1                # Static image export for Plotly

### --- SYSTEM / UTILITIES ---
tqdm==4.67.1                  # Progress bar for batch jobs
rich==13.9.3                  # Console visualization (pretty logs)
loguru==0.7.3                 # Logging handler (backend/reporting)

---



ðŸ”® Future Extensions
Add Voice Sentiment Recognition (acoustic + linguistic fusion)

Expand Multilingual Support (local cultural tones)

Integrate Adaptive Questioning (context-aware probing)

Include Explainable AI layer for model transparency

ðŸ§­ â€œThe reliability of an interview is the reliability of its evaluator â€” hence we build one that never drifts.